{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define the number of data points for each scenario based on the plan\n",
    "N_POINTS_NORMAL = 20000\n",
    "N_POINTS_DEGRADATION = 5000\n",
    "N_POINTS_INTERFERENCE = 5000\n",
    "N_POINTS_INTERMITTENT = 5000\n",
    "N_POINTS_SYNC = 5000\n",
    "TOTAL_POINTS = N_POINTS_NORMAL + N_POINTS_DEGRADATION + N_POINTS_INTERFERENCE + N_POINTS_INTERMITTENT + N_POINTS_SYNC\n",
    "\n",
    "# Define the columns for the final dataset, now including the 'Scenario' column\n",
    "COLUMNS = [\n",
    "    \"Timestamp\", \"Scenario\", \"SNR\", \"RSSI\", \"BER\", \"EVM\",\n",
    "    \"Phase_Offset\", \"Frequency_Offset\", \"Label\"\n",
    "]\n",
    "# Define the feature columns (excluding metadata and label) for DataFrame creation\n",
    "FEATURE_COLUMNS = [\n",
    "    \"SNR\", \"RSSI\", \"BER\", \"EVM\", \"Phase_Offset\", \"Frequency_Offset\", \"Label\"\n",
    "]\n",
    "\n",
    "\n",
    "# --- Scenario Generation Functions ---\n",
    "\n",
    "def generate_normal_data(n_points):\n",
    "    \"\"\"Generates data for Scenario 1: Normal Operation.\"\"\"\n",
    "    print(f\"Generating {n_points} data points for Normal Operation...\")\n",
    "    snr_levels = [18, 22, 25]\n",
    "    snr = np.random.choice(snr_levels, n_points) + np.random.normal(0, 0.5, n_points)\n",
    "    rssi = -40 + snr/5 + np.random.normal(0, 0.5, n_points)\n",
    "    ber = np.zeros(n_points)\n",
    "    evm = np.random.uniform(0.5, 1.5, n_points)\n",
    "    phase_offset = np.random.normal(0, 0.05, n_points)\n",
    "    frequency_offset = np.random.normal(0, 0.01, n_points)\n",
    "    label = np.zeros(n_points, dtype=int)\n",
    "    \n",
    "    return pd.DataFrame(data=zip(snr, rssi, ber, evm, phase_offset, frequency_offset, label),\n",
    "                        columns=FEATURE_COLUMNS)\n",
    "\n",
    "def generate_gradual_degradation_data(n_points):\n",
    "    \"\"\"Generates data for Scenario 2: Gradual Degradation.\"\"\"\n",
    "    print(f\"Generating {n_points} data points for Gradual Degradation...\")\n",
    "    snr = np.linspace(20, 5, n_points) + np.random.normal(0, 0.5, n_points)\n",
    "    rssi = -40 + snr/5 + np.random.normal(0, 1, n_points)\n",
    "    ber = np.maximum(0, (10 - snr) * 0.01) * np.random.uniform(0.5, 1.5, n_points)\n",
    "    ber[snr > 10] = 0\n",
    "    \n",
    "    # *** DEFINITIVE FIX: Add noise first, then clamp the entire result to 0 ***\n",
    "    base_evm = 20 - (snr * 0.9)\n",
    "    noise = np.random.normal(0, 1, n_points)\n",
    "    evm = np.maximum(0, base_evm + noise)\n",
    "    \n",
    "    phase_offset = np.linspace(0.1, 0.8, n_points) + np.random.normal(0, 0.1, n_points)\n",
    "    frequency_offset = np.linspace(0.05, 0.3, n_points) + np.random.normal(0, 0.05, n_points)\n",
    "    label = np.ones(n_points, dtype=int)\n",
    "    \n",
    "    return pd.DataFrame(data=zip(snr, rssi, ber, evm, phase_offset, frequency_offset, label),\n",
    "                        columns=FEATURE_COLUMNS)\n",
    "\n",
    "def generate_sudden_interference_data(n_points):\n",
    "    \"\"\"Generates data for Scenario 3: Sudden Interference.\"\"\"\n",
    "    print(f\"Generating {n_points} data points for Sudden Interference...\")\n",
    "    snr = np.full(n_points, 25.0) + np.random.normal(0, 0.5, n_points)\n",
    "    rssi = -40 + snr/5 + np.random.normal(0, 0.5, n_points)\n",
    "    ber = np.zeros(n_points)\n",
    "    evm = np.random.uniform(0.5, 1.5, n_points)\n",
    "    phase_offset = np.random.normal(0, 0.05, n_points)\n",
    "    frequency_offset = np.random.normal(0, 0.01, n_points)\n",
    "    \n",
    "    drop_start = int(n_points * 0.45)\n",
    "    drop_end = int(n_points * 0.55)\n",
    "    snr[drop_start:drop_end] = np.random.uniform(-5, 0, drop_end - drop_start)\n",
    "    rssi[drop_start:drop_end] += np.random.uniform(-10, -5, drop_end - drop_start)\n",
    "    ber[drop_start:drop_end] = np.random.uniform(0.1, 0.4, drop_end - drop_start)\n",
    "    evm[drop_start:drop_end] = np.random.uniform(20, 40, drop_end - drop_start)\n",
    "    phase_offset[drop_start:drop_end] += np.random.normal(0, 0.5, drop_end - drop_start)\n",
    "    frequency_offset[drop_start:drop_end] += np.random.normal(0, 0.2, drop_end - drop_start)\n",
    "    \n",
    "    label = np.ones(n_points, dtype=int)\n",
    "    \n",
    "    return pd.DataFrame(data=zip(snr, rssi, ber, evm, phase_offset, frequency_offset, label),\n",
    "                        columns=FEATURE_COLUMNS)\n",
    "\n",
    "def generate_intermittent_faults_data(n_points):\n",
    "    \"\"\"Generates data for Scenario 4: Intermittent Faults.\"\"\"\n",
    "    print(f\"Generating {n_points} data points for Intermittent Faults...\")\n",
    "    base_snr = 12\n",
    "    t = np.linspace(0, 10 * np.pi, n_points)\n",
    "    snr = base_snr + 4 * np.sin(t) + np.random.normal(0, 1, n_points)\n",
    "    rssi = -45 + snr/6 + np.random.normal(0, 1.5, n_points)\n",
    "    ber = np.maximum(0, (12 - snr) * 0.005) * np.random.uniform(0.5, 1.5, n_points)\n",
    "    \n",
    "    # *** DEFINITIVE FIX: Add noise first, then clamp the entire result to 0 ***\n",
    "    base_evm = 18 - (snr * 0.8)\n",
    "    noise = np.random.normal(0, 2, n_points)\n",
    "    evm = np.maximum(0, base_evm + noise)\n",
    "\n",
    "    phase_offset = 0.2 + np.sin(t/2) * 0.5 + np.random.normal(0, 0.2, n_points)\n",
    "    frequency_offset = 0.1 + np.sin(t/3) * 0.2 + np.random.normal(0, 0.1, n_points)\n",
    "    label = np.ones(n_points, dtype=int)\n",
    "    \n",
    "    return pd.DataFrame(data=zip(snr, rssi, ber, evm, phase_offset, frequency_offset, label),\n",
    "                        columns=FEATURE_COLUMNS)\n",
    "\n",
    "def generate_sync_issues_data(n_points):\n",
    "    \"\"\"Generates data for Scenario 5: Synchronization Issues.\"\"\"\n",
    "    print(f\"Generating {n_points} data points for Synchronization Issues...\")\n",
    "    snr = np.full(n_points, 15.0) + np.random.normal(0, 1, n_points)\n",
    "    rssi = -42 + np.random.normal(0, 1, n_points)\n",
    "    phase_offset = np.linspace(1.5, 2.5, n_points) + np.random.normal(0, 0.1, n_points)\n",
    "    frequency_offset = np.linspace(0.8, 1.2, n_points) + np.random.normal(0, 0.05, n_points)\n",
    "    ber = np.random.uniform(0.01, 0.05, n_points)\n",
    "    evm = np.random.uniform(8, 15, n_points)\n",
    "    label = np.ones(n_points, dtype=int)\n",
    "    \n",
    "    return pd.DataFrame(data=zip(snr, rssi, ber, evm, phase_offset, frequency_offset, label),\n",
    "                        columns=FEATURE_COLUMNS)\n",
    "\n",
    "# --- Main Script Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate data for each scenario\n",
    "    df_normal = generate_normal_data(N_POINTS_NORMAL)\n",
    "    df_degradation = generate_gradual_degradation_data(N_POINTS_DEGRADATION)\n",
    "    df_interference = generate_sudden_interference_data(N_POINTS_INTERFERENCE)\n",
    "    df_intermittent = generate_intermittent_faults_data(N_POINTS_INTERMITTENT)\n",
    "    df_sync = generate_sync_issues_data(N_POINTS_SYNC)\n",
    "    \n",
    "    # Add a 'Scenario' column to each dataframe BEFORE concatenating\n",
    "    df_normal['Scenario'] = 'Normal'\n",
    "    df_degradation['Scenario'] = 'Gradual_Degradation'\n",
    "    df_interference['Scenario'] = 'Sudden_Interference'\n",
    "    df_intermittent['Scenario'] = 'Intermittent_Faults'\n",
    "    df_sync['Scenario'] = 'Sync_Issues'\n",
    "    \n",
    "    # Combine all dataframes into one\n",
    "    print(\"\\nCombining all scenarios into a single dataset...\")\n",
    "    final_df = pd.concat([\n",
    "        df_normal,\n",
    "        df_degradation,\n",
    "        df_interference,\n",
    "        df_intermittent,\n",
    "        df_sync\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    # Add a timestamp column (e.g., in seconds)\n",
    "    final_df['Timestamp'] = np.arange(TOTAL_POINTS) * 0.01 # Assuming 10ms intervals\n",
    "    \n",
    "    # Reorder columns to the desired final order\n",
    "    final_df = final_df[COLUMNS]\n",
    "    \n",
    "    # CRITICAL STEP: Shuffle the dataset to randomize the order of scenarios\n",
    "    print(\"Shuffling the dataset...\")\n",
    "    final_df = final_df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # Save the final dataset to a CSV file\n",
    "    output_filename = \"eVTOL_telemetry_dataset_v3.csv\"\n",
    "    print(f\"Saving the final, corrected dataset to {output_filename}...\")\n",
    "    final_df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(\"\\n--- Dataset Generation Complete ---\")\n",
    "    print(f\"Total data points: {len(final_df)}\")\n",
    "    print(\"Class distribution:\")\n",
    "    print(final_df['Label'].value_counts())\n",
    "    print(\"\\nFirst 5 rows of the final dataset:\")\n",
    "    print(final_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global-suicide-eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
